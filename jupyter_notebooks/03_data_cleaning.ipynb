{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Data Cleaning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Prepare the data sets for further analysis\n",
        "\n",
        "<br>\n",
        "\n",
        "* Load and inspect the data prepared during data collection\n",
        "* Data exploration\n",
        "* Correlation and PPS study\n",
        "* Data Cleaning\n",
        "* Conclusion and next steps\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* inputs/datasets/raw/house-price-20211124T154130Z-001/house-price/house_prices_records.csv\n",
        "* inputs/datasets/raw/house-price-20211124T154130Z-001/house-price/inherited_houses.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* outputs/datasets/cleaned/train_set.csv\n",
        "* outputs/datasets/cleaned/test_set.csv\n",
        "* outputs/datasets/cleaned/clean_house_price_records.csv\n",
        "* outputs/datasets/cleaned/clean_inherited_houses.csv\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* This notebook was written based on the guidelines provided in the Customer Churn walk through project, data cleaning lesson.\n",
        "* This notebook relates to the Data Preparation step of Crisp-DM methodology"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "Change the working directory from its current folder to its parent folder\n",
        "* Access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "Make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import Packages and set environment variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.options.display.max_columns = None\n",
        "from pandas_profiling import ProfileReport\n",
        "from feature_engine.imputation import ArbitraryNumberImputer, CategoricalImputer\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Load the data downloaded in the data collection notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(f\"inputs/datasets/raw/house-price-20211124T154130Z-001/house-price/house_prices_records.csv\")\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_inherited = pd.read_csv(f\"inputs/datasets/raw/house-price-20211124T154130Z-001/house-price/inherited_houses.csv\")\n",
        "print(df_inherited.shape)\n",
        "df_inherited"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Explore the dataset, check variable types and distribution, missing levels and what value these variables may add in the context of the first business requirement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* First list the variables that are missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vars_missing_data = df.columns[df.isna().sum() > 0].to_list()\n",
        "vars_missing_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Run a pandas profiling report using only the `var_missing_data` variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if vars_missing_data:\n",
        "   pandas_report = ProfileReport(df=df[vars_missing_data], minimal=True)\n",
        "   pandas_report.to_notebook_iframe()\n",
        "else:\n",
        "   print(\"There are no variables with missing data.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Correlation and PPS Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In this section I want to understand how the target variable, SalePrice, correlates with the features.\n",
        "* I am using the same code from the PPS (power predictive score) lesson, to build heatmaps for pearson and spearman correlation, as well as a PPS heatmap."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import ppscore as pps\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "def heatmap_corr(df, threshold, figsize=(20,12), font_annot = 8):\n",
        "  if len(df.columns) > 1:\n",
        "    mask = np.zeros_like(df, dtype=bool)\n",
        "    mask[np.triu_indices_from(mask)] = True\n",
        "    mask[abs(df) < threshold] = True\n",
        "\n",
        "    fig, axes = plt.subplots(figsize=figsize)\n",
        "    sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
        "                mask=mask, cmap='viridis', annot_kws={\"size\": font_annot}, ax=axes,\n",
        "                linewidth=0.5\n",
        "                     )\n",
        "    axes.set_yticklabels(df.columns, rotation = 0)\n",
        "    plt.ylim(len(df.columns),0)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def heatmap_pps(df, threshold, figsize=(20,12), font_annot = 8):\n",
        "    if len(df.columns) > 1:\n",
        "\n",
        "      mask = np.zeros_like(df, dtype=bool)\n",
        "      mask[abs(df) < threshold] = True\n",
        "\n",
        "      fig, ax = plt.subplots(figsize=figsize)\n",
        "      ax = sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
        "                       mask=mask,cmap='rocket_r', annot_kws={\"size\": font_annot},\n",
        "                       linewidth=0.05, linecolor='grey')\n",
        "      \n",
        "      plt.ylim(len(df.columns),0)\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def CalculateCorrAndPPS(df):\n",
        "  df_corr_spearman = df.corr(method=\"spearman\")\n",
        "  df_corr_pearson = df.corr(method=\"pearson\")\n",
        "\n",
        "  pps_matrix_raw = pps.matrix(df)\n",
        "  pps_matrix = pps_matrix_raw.filter(['x', 'y', 'ppscore']).pivot(columns='x', index='y', values='ppscore')\n",
        "\n",
        "  pps_score_stats = pps_matrix_raw.query(\"ppscore < 1\").filter(['ppscore']).describe().T\n",
        "  print(\"PPS threshold - check PPS score IQR to decide threshold for heatmap \\n\")\n",
        "  print(pps_score_stats.round(3))\n",
        "\n",
        "  return df_corr_pearson, df_corr_spearman, pps_matrix\n",
        "\n",
        "\n",
        "def DisplayCorrAndPPS(df_corr_pearson, df_corr_spearman, pps_matrix, CorrThreshold, PPS_Threshold,\n",
        "                      figsize=(20,12), font_annot=8 ):\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"* Here I can analyze how the target variable for your ML models are correlated with other variables (features and target)\")\n",
        "  print(\"* Analyze multi colinearity, that is, how the features are correlated among themselves\")\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Spearman Correlation ***\")\n",
        "  print(\"It evaluates monotonic relationships between variables \\n\")\n",
        "  heatmap_corr(df=df_corr_spearman, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Pearson Correlation ***\")\n",
        "  print(\"It evaluates the linear relationship between two continuous variables \\n\")\n",
        "  heatmap_corr(df=df_corr_pearson, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Power Predictive Score (PPS) ***\")\n",
        "  print(f\"PPS detects linear or non-linear relationships between two columns.\\n\"\n",
        "        f\"The score ranges from 0 (no predictive power) to 1 (perfect predictive power) \\n\")\n",
        "  heatmap_pps(df=pps_matrix,threshold=PPS_Threshold, figsize=figsize, font_annot=font_annot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Calculate Correlations and Power Predictive Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_corr_pearson, df_corr_spearman, pps_matrix = CalculateCorrAndPPS(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* The table above shows the most common levels for pps scores in the matrix. The majority are between 0 and 0.066."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Display correlation and pps results on Heatmaps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DisplayCorrAndPPS(df_corr_pearson = df_corr_pearson,\n",
        "                  df_corr_spearman = df_corr_spearman, \n",
        "                  pps_matrix = pps_matrix,\n",
        "                  CorrThreshold = 0.6, PPS_Threshold = 0.2,\n",
        "                  figsize=(12,10), font_annot=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Dataset Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Data Exploration\n",
        "\n",
        "* The data profiling report shows that there are fields that contain many zero values, more concerning though, is the number of variables that do not contain data. ie. contain null values.\n",
        "  * I will examine these variables and explore whether there is common criteria that may assist in imputing data into these variables or whether in some case it is viable to drop the feature completely\n",
        "  * I will then do a correlation study and compare the before and after results to establish whether this exercise makes a difference to predicting sale price\n",
        "\n",
        "### Correlation and PPS Analysis\n",
        "* Note the results show a number of variables to be moderate to strong predictors for other variables, most asynchronously.\n",
        "* However, I am interested in variables that are predictors of Sale Price.\n",
        "  * From the results of both the correlation and PPS studies, I see that the strongest predictor of Sale Price (SalePrice) is Overall Quality (OverallQual) of the property.\n",
        "  * Overall the correlation study shows 6 features that are positively and strongly correlated to SalePrice, namely:\n",
        "    * 1stFlrSF, GarageArea, GrLivArea, OverallQual, TotalBsmtSF, YearBuilt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " `DataCleaningEffect()` taken from `ML Feature Engine Unit 9: Custom Functions`\n",
        "* Function objective: assess the effect of cleaning the data, when\n",
        "  * imput mean, median or arbitrary number is a numerical variable\n",
        "  * replace with 'Missing' or most frequent a categorical variable\n",
        "* Parameters: `df_original`: data not cleaned, `df_cleaned`: cleaned data, `variables_applied_with_method`: variables where you applied a given method\n",
        "\n",
        "  * It is understandable if, at first, you don't understand all code from the function below. The point is to make sense of the pseudo-code and understand the function parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "sns.set(style=\"whitegrid\")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def DataCleaningEffect(df_original,df_cleaned,variables_applied_with_method):\n",
        "\n",
        "  flag_count=1 # Indicate plot number\n",
        "  \n",
        "  # distinguish between numerical and categorical variables\n",
        "  categorical_variables = df_original.select_dtypes(exclude=['number']).columns \n",
        "\n",
        "  # scan over variables, \n",
        "    # first on variables that you applied the method\n",
        "    # if the variable is numerical plot a histogram, if categorical plot a barplot\n",
        "  for set_of_variables in [variables_applied_with_method]:\n",
        "    print(\"\\n=====================================================================================\")\n",
        "    print(f\"* Distribution Effect Analysis After Data Cleaning Method in the following variables:\")\n",
        "    print(f\"{set_of_variables} \\n\\n\")\n",
        "  \n",
        "\n",
        "    for var in set_of_variables:\n",
        "      if var in categorical_variables:  # it is categorical variable: barplot\n",
        "        \n",
        "        df1 = pd.DataFrame({\"Type\":\"Original\",\"Value\":df_original[var]})\n",
        "        df2 = pd.DataFrame({\"Type\":\"Cleaned\",\"Value\":df_cleaned[var]})\n",
        "        dfAux = pd.concat([df1, df2], axis=0)\n",
        "        fig , axes = plt.subplots(figsize=(15, 5))\n",
        "        sns.countplot(hue='Type', data=dfAux, x=\"Value\",palette=['#432371',\"#FAAE7B\"])\n",
        "        axes.set(title=f\"Distribution Plot {flag_count}: {var}\")\n",
        "        plt.xticks(rotation=90)\n",
        "        plt.legend() \n",
        "\n",
        "      else: # it is numerical variable: histogram\n",
        "\n",
        "        fig , axes = plt.subplots(figsize=(10, 5))\n",
        "        sns.histplot(data=df_original, x=var, color=\"#432371\", label='Original', kde=True,element=\"step\", ax=axes)\n",
        "        sns.histplot(data=df_cleaned, x=var, color=\"#FAAE7B\", label='Cleaned', kde=True,element=\"step\", ax=axes)\n",
        "        axes.set(title=f\"Distribution Plot {flag_count}: {var}\")\n",
        "        plt.legend() \n",
        "\n",
        "      plt.show()\n",
        "      flag_count+= 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Assessing Missing Data Levels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Custom function to display missing data levels in a dataframe, it shows the aboslute levels, relative levels and data type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def EvaluateMissingData(df):\n",
        "  missing_data_absolute = df.isnull().sum()\n",
        "  missing_data_percentage = round(missing_data_absolute/len(df)*100 , 2)\n",
        "  df_missing_data = (pd.DataFrame(\n",
        "                          data= {\"RowsWithMissingData\": missing_data_absolute,\n",
        "                                 \"PercentageOfDataset\": missing_data_percentage,\n",
        "                                 \"DataType\":df.dtypes}\n",
        "                                  )\n",
        "                    .sort_values(by=['PercentageOfDataset'],ascending=False)\n",
        "                    .query(\"PercentageOfDataset > 0\")\n",
        "                    )\n",
        "\n",
        "  return df_missing_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EvaluateMissingData(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a clean dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data cleaning approach\n",
        "\n",
        "* Investigate variables listed with missing data\n",
        "* Drop EnclosedPorch and WoodDeckSF - more than 80% null values\n",
        "* Other fields may possibly be imputed with valid value or median\n",
        "\n",
        "Note:\n",
        " The 6 features that show positively and strongly correlation to SalePrice, are not listed among the variables that contain null values.\n",
        "   * 1stFlrSF, GarageArea, GrLivArea, OverallQual, TotalBsmtSF, YearBuilt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a copy of the house price records dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_clean = df.copy()\n",
        "print(df_clean.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split the dataset into Train and Test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_set, test_set, _, __ = train_test_split(\n",
        "                                        df,\n",
        "                                        df['SalePrice'],\n",
        "                                        test_size=0.2,\n",
        "                                        random_state=0)\n",
        "\n",
        "print(f\"train_set shape: {train_set.shape} \\ntest_set shape: {test_set.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluate train_set Missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_missing_data = EvaluateMissingData(train_set)\n",
        "print(f\"* There are {df_missing_data.shape[0]} variables with missing data \\n\")\n",
        "df_missing_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Individual variable analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Variables to consider dropping\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Inspect `WoodDeckSF` and `EnclosedPorch` variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_wooddecksf = train_set.loc[train_set['WoodDeckSF'].notnull()]\n",
        "df_wooddecksf[['WoodDeckSF', 'SalePrice']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_wooddecksf['WoodDeckSF'].value_counts().sort_index(ascending=False).head(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### EnclosedPorch - Enclosed porch area in square feet\n",
        "When evaluating missing data we can see that this variable contains more than 90% null values. Therefore, I deduce that this variable will add no value to the sale price analysis. In the inherited dataset the value for this variable is 0 for all 4 properties, meaning the porch is not enclosed. In addition, the `Correlation and PPS Analysis` shows that this field has no predictive power.\n",
        "\n",
        "#### WoodDeckSF - Wood deck area in square feet\n",
        "This variable contains approximately 89% null values. In the inherited dataset this field contains valid values, however, due to the lack of comparative data in the train set, this variable may add no value at all. Furthermore, doing a value count shows the data contains diverse sizes and not enough uniqueness, and little to no exact matches to the inherited house dataset. In addition, the `Correlation and PPS Analysis` shows that this field has no predictive power.\n",
        "\n",
        "#### Conclusion\n",
        "Drop both `EnclosedPorch` and `WoodDeckSF` using `feature_engine's DropFeatures` method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.selection import DropFeatures\n",
        "variables = ['EnclosedPorch', 'WoodDeckSF']\n",
        "imputer = DropFeatures(features_to_drop=variables)\n",
        "imputer.fit(train_set)\n",
        "train_set, test_set = imputer.transform(train_set), imputer.transform(test_set)\n",
        "train_set.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Drop the features from the inherited houses dataset as well"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_clean = imputer.transform(df_clean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "null_variables = train_set.columns[train_set.isnull().any()].tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Variables to consider transforming or imputing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Inspect `LotFrontage` and `MasVnrArea` variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set['LotFrontage'].value_counts().sort_index(ascending=False).head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set['MasVnrArea'].value_counts().sort_index(ascending=False).head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* The PPS score on LotFrontage and MasVnrArea shows these fields have no predictive power.\n",
        "* The correlation study shows they have a moderate correlation to the SalePrice\n",
        "* On inspecting the dataset, for these variables, it is noted that in relation to other variables there is no way of identifying or deriving possible valid values for imputing on null variables\n",
        "\n",
        "#### Conclusion\n",
        "\n",
        "Use `MeanMedianImputer` to impute a `Median` value into the null variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.imputation import MeanMedianImputer\n",
        "variables = ['LotFrontage', 'MasVnrArea']\n",
        "imputer = MeanMedianImputer(imputation_method='median', variables=variables)\n",
        "imputer.fit(train_set)\n",
        "train_set, test_set = imputer.transform(train_set), imputer.transform(test_set)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_clean = imputer.transform(df_clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EvaluateMissingData(train_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Missing data evaluation shows that `EnclosedPorch`, `WoodDeckSF`, `LotFrontage` and `MasVnrArea` no longer appear on the list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2ndFlrSF - Second floor square feet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Inspect `2ndFlrSF` variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set['2ndFlrSF'].value_counts().sort_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* `60` variables of `1168` contain null values. When studying the data, it appears that if there is no second floor the value would be set to `0`. More than 50% of values for this variable are 0. Therefore one may deduce imputing the null values with 0 would add value.\n",
        "* We prepare the pipeline to use `ArbitraryNumberImputer` to impute `0` into the null variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### BedroomAbvGr - Bedrooms above grade (does NOT include basement bedrooms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Inspect `BedroomAbvGr` variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set['BedroomAbvGr'].value_counts().sort_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* `80` variables of `1168` contain null values. A value count shows that only 4 records have a `0` for this variable. All 4 inherited properties contain values above zero. Imputing the null values with 0 may have no effect on the sales price analysis but I deduce that `0` grading is equivalent to `null` grading.\n",
        "* Prepare the pipeline to use `ArbitraryNumberImputer` to impute `0` into the null variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline = Pipeline([\n",
        "      ( '2ndFlrSF',  ArbitraryNumberImputer(arbitrary_number=0,\n",
        "                                                variables=['2ndFlrSF', 'BedroomAbvGr']) )\n",
        "])\n",
        "pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline.fit(train_set)\n",
        "train_set, test_set = pipeline.transform(train_set), pipeline.transform(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "df_clean = pipeline.transform(df_clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EvaluateMissingData(train_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Missing data evaluation shows that `2ndFlrSF` and `BedroomAbvGr` no longer appear on the list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### BsmtFinType1 - Rating of basement finished area"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Inspect `BsmtFinType1` variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set['BsmtFinType1'].value_counts().sort_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Inspect `BsmtExposure` variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set['BsmtExposure'].value_counts().sort_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set[train_set['BsmtFinType1'].isna()].query('BsmtExposure==\"None\"').sort_values(by=['BsmtExposure'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* `89` variables of `1168` contain null values. There are only `25` properties with no basement.\n",
        "* `BsmtExposure` however contains no null variables and on comparing the two fields I established that there are `3` rows that are set to `None`, meaning that they have no basement, where `BsmtFinType1` is null. For these `3` rows the `BsmtFinType1` variable may be imputed with `None`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query_condition = (train_set.BsmtExposure == 'None') & (train_set['BsmtFinType1'].isnull())\n",
        "train_set['BsmtFinType1'] = np.where(query_condition, 'None', train_set['BsmtFinType1'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query_condition = (test_set.BsmtExposure == 'None') & (test_set['BsmtFinType1'].isnull())\n",
        "test_set['BsmtFinType1'] = np.where(query_condition, 'None', test_set['BsmtFinType1'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query_condition = (df_clean.BsmtExposure == 'None') & (df_clean['BsmtFinType1'].isnull())\n",
        "df_clean['BsmtFinType1'] = np.where(query_condition, 'None', df_clean['BsmtFinType1'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set[train_set['BsmtFinType1'].isna()].query('BsmtExposure==\"None\"').sort_values(by=['BsmtExposure'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* The `3` rows have been imputed with `None` and hence no longer appear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set['BsmtFinType1'].isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* There are still `86 BsmtFinType1` containing nulls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Inspect `BsmtFinSF1` variable. Type 1 finished square feet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_temp = train_set[train_set['BsmtFinType1'].isna()].query('BsmtFinSF1==0').sort_values(by=['BsmtFinSF1'])\n",
        "print(df_temp.shape)\n",
        "df_temp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Next we look at `BsmtFinSF1` which contains no null variables. We search for `BsmtFinType1` with nulls and `BsmtFinSF1` with value `0`, meaning `0` finished square feet, which means unfinished. We find there are 27 records. Therefore, we can impute these records with `Unf` which means unfinished for `BsmtFinType1` variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query_condition = (train_set.BsmtFinSF1 == 0) & (train_set['BsmtFinType1'].isnull())\n",
        "train_set['BsmtFinType1'] = np.where(query_condition, 'Unf', train_set['BsmtFinType1'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query_condition = (test_set.BsmtFinSF1 == 0) & (test_set['BsmtFinType1'].isnull())\n",
        "test_set['BsmtFinType1'] = np.where(query_condition, 'Unf', test_set['BsmtFinType1'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query_condition = (df_clean.BsmtFinSF1 == 0) & (df_clean['BsmtFinType1'].isnull())\n",
        "df_clean['BsmtFinType1'] = np.where(query_condition, 'Unf', df_clean['BsmtFinType1'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set[train_set['BsmtFinType1'].isna()].query('BsmtFinSF1==0').sort_values(by=['BsmtFinSF1']).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* The `27` rows have been imputed with `Unf` and hence no longer appear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set['BsmtFinType1'].isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* There are still `59 BsmtFinType1` containing nulls. These remaing null variables will be imputed with `Unk` meaning `Unknown`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "imputer = CategoricalImputer(imputation_method='missing',fill_value='Unk',\n",
        "                             variables='BsmtFinType1')\n",
        "\n",
        "imputer.fit(train_set)\n",
        "train_set, test_set, df_clean = imputer.transform(train_set), imputer.transform(test_set), imputer.transform(df_clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set['BsmtFinType1'].isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are no null values in `BsmtFinType1`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Inspect `GarageFinish` variable. Interior finish of the garage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set['GarageFinish'].isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* There are `131` null variables for `GarageFinish`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set['GarageFinish'].value_counts().sort_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set.loc[train_set.GarageFinish==\"None\",'GarageArea'].value_counts()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Note above, where `GarageFinish==\"None\"`, meaning there is no garage, `GarageArea` is found to be `0`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set.loc[train_set.GarageFinish.isnull(),'GarageArea'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Therefore, where `GarageFinish` is null we can check if `GarageArea` is `0` and if so we can impute `None` on `GarageFinish`.\n",
        "* Based on the above query, only `5` rows will be affected.\n",
        "* For the remaining records we will assume that the garages are unfinished and hence impute `Unf` on `GarageFinish`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query_condition = (train_set.GarageArea == 0) & (train_set['GarageFinish'].isnull())\n",
        "train_set['GarageFinish'] = np.where(query_condition, 'None', train_set['GarageFinish'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query_condition = (test_set.GarageArea == 0) & (test_set['GarageFinish'].isnull())\n",
        "test_set['GarageFinish'] = np.where(query_condition, 'None', test_set['GarageFinish'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query_condition = (df_clean.GarageArea == 0) & (df_clean['GarageFinish'].isnull())\n",
        "df_clean['GarageFinish'] = np.where(query_condition, 'None', df_clean['GarageFinish'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set['GarageFinish'].isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline = Pipeline([\n",
        "      ( 'categorical_imputer', CategoricalImputer(imputation_method='missing',\n",
        "                                                  fill_value='Unf',\n",
        "                                                  variables=['GarageFinish']) )\n",
        "])\n",
        "pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline.fit(train_set)\n",
        "\n",
        "train_set, test_set = pipeline.transform(train_set), pipeline.transform(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_clean = pipeline.transform(df_clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set['GarageFinish'].isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are no null values in `GarageFinish`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Inspect `GarageYrBlt` variable. Year garage was built."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set['GarageYrBlt'].isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Get a row count of where `GarageYrBlt` is null, and return the value of `GarageFinish`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set.loc[train_set.GarageYrBlt.isnull(),'GarageFinish'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set[train_set.GarageFinish=='None']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Note there are `58` null records for the `GarageYrBlt` and where this variable is null `GarageFinish` is `None`, meaning there is no garage.\n",
        "* Prepare a pipeline to use `ArbitraryNumberImputer` to impute `0` into the null variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline = Pipeline([\n",
        "      ( 'GarageYrBlt',  ArbitraryNumberImputer(arbitrary_number=0,\n",
        "                                                variables='GarageYrBlt') )\n",
        "])\n",
        "pipeline\n",
        "\n",
        "pipeline.fit(train_set)\n",
        "train_set, test_set = pipeline.transform(train_set), pipeline.transform(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_clean = pipeline.transform(df_clean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Show missing data evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EvaluateMissingData(train_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EvaluateMissingData(df_clean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* There are no variables missing data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Before and After comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Assess the effect on the variable distribution\n",
        "* The function plots in the same Axes the distribution before and after applying the method. This helps to give you insights into how different your variable would look after cleaning.\n",
        "* We notice the \"peak\" in the variable distribution after median imputation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DataCleaningEffect(df_original=df,\n",
        "                   df_cleaned=df_clean,\n",
        "                   variables_applied_with_method=null_variables)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Datatype changes - `Float` to `Integer`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On examining the data in the heritage houses dataset, we can see that there are no float values in the float columns so we will change these to int."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df_clean.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_clean.select_dtypes('float').info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for col in df_clean.select_dtypes('float').columns:\n",
        "    df_clean[col] = df_clean[col].astype('int64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_clean.select_dtypes('float').info()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On examining the data in the inherited houses dataset, we can see that there are no float values in the float columns so we will change these to int."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for col in df_inherited.select_dtypes('float').columns:\n",
        "    df_inherited[col] = df_inherited[col].astype('int64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_inherited.select_dtypes('float').info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_inherited.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Change float columns to int for train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for col in train_set.select_dtypes('float').columns:\n",
        "    train_set[col] = train_set[col].astype('int64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for col in test_set.select_dtypes('float').columns:\n",
        "    test_set[col] = test_set[col].astype('int64')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Save Train and Test sets to csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Create a cleaned folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  os.makedirs(name='outputs/datasets/cleaned') # create outputs/datasets/collection folder\n",
        "except Exception as e:\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* output the clean datasets to csv files into the outputs/datasets folder\n",
        "* outputs/datasets/cleaned/train_set.csv\n",
        "* outputs/datasets/cleaned/test_set.csv\n",
        "* outputs/datasets/cleaned/clean_house_price_records.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set.to_csv(\"outputs/datasets/cleaned/train_set.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_set.to_csv(\"outputs/datasets/cleaned/test_set.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_clean.to_csv(\"outputs/datasets/cleaned/clean_house_price_records.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_inherited.to_csv(\"outputs/datasets/cleaned/clean_inherited_houses.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusions and Next Steps\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Created clean version of the housing price dataset and the inherited houses datasets\n",
        "* On the inherited dataset the only step taken was to drop the variables `EnclosedPorch` and `WoodDeckSF`\n",
        "* The housing price dataset was also split into Train and Test set.\n",
        "* The clean datasets were saved to csv files, in the outputs/datasets/cleaned folder:\n",
        "  * clean_house_price_records.csv\n",
        "  * clean_inherited_houses.csv\n",
        "  * train_set.csv\n",
        "  * test_set.csv\n",
        "* Now we move on to the Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12 (default, Nov  4 2022, 14:27:31) \n[GCC 9.4.0]"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
